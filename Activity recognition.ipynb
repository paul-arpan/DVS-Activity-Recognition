{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataLoader class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import av\n",
    "import re\n",
    "from itertools import cycle\n",
    "from random import shuffle\n",
    "\n",
    "class videoDataset():\n",
    "    \"\"\"Dataset Class for Loading Video\"\"\"\n",
    "\n",
    "    def __init__(self, path):\n",
    "        \n",
    "        self.rootDir = path\n",
    "        name=[]\n",
    "        file=[]\n",
    "        for _, dirnames, filenames in os.walk(path):\n",
    "            name.append(dirnames)\n",
    "            file.append(filenames)\n",
    "        name = name[0]\n",
    "\n",
    "        newpath = []\n",
    "\n",
    "        for i in range(len(name)):    \n",
    "            for files in file[i+1]:\n",
    "                pathn = path + name[i]+'/' + files\n",
    "                newpath.append(pathn)\n",
    "                \n",
    "        shuffle(newpath)        \n",
    "        self.sequenceLength = 5\n",
    "        self.classList=['(0_Basketball)','(1_Biking)','(2_Diving)','(3_GolfSwing)','(4_HorseRiding)','(5_SoccerJuggling)','(6_Swing)','(7_TennisSwing)','(8_TrampolineJumping)','(9_VolleyballSpiking)','(10_WalkingWithDog)']\t# Word 1   \n",
    "        self.Xaxis = 192\n",
    "        self.Yaxis = 240\n",
    "        self.minFrames = 31        \n",
    "        self.pathList = cycle(newpath)\n",
    "        self.testdata = []\n",
    "        self.batchsize = 50\n",
    "        self.k = 1\n",
    "        self.current=0\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    " \n",
    "    \n",
    "    def frameLength(newpath):\n",
    "        v = av.open(newpath)\n",
    "        stream = next(s for s in v.streams if s.type == 'video')\n",
    "        #X_data = []\n",
    "        for packet in v.demux(stream):\n",
    "            for frame in packet.decode():\n",
    "                continue\n",
    "        return frame.index\n",
    "    \n",
    "    def setK(self,num):\n",
    "        self.k = num\n",
    "    \n",
    " \n",
    "    def regexBatchnum(self,path):\n",
    "        re1='.*?'\t# Non-greedy match on filler\n",
    "        re2='g'\t# Uninteresting: c\n",
    "        re3='.*?'\t# Non-greedy match on filler\n",
    "        re4='g'\t# Uninteresting: c\n",
    "        re5='.*?'\t# Non-greedy match on filler\n",
    "        re6='g'\t# Uninteresting: c\n",
    "        re7='.*?'\t# Non-greedy match on filler\n",
    "        re8='(g)'\t# Any Single Character 1        \n",
    "\n",
    "        re9= '(' + str(self.k).zfill(2) + ')'\t# Integer Number 1\n",
    "        \n",
    "        rg = re.compile(re1+re2+re3+re4+re5+re6+re7+re8+re9,re.IGNORECASE|re.DOTALL)\n",
    "        m = rg.search(path)\n",
    "        \n",
    "        if(m==None):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    \n",
    "    def regexClass(self,path):\n",
    "        \n",
    "        classnum = 0\n",
    "                \n",
    "        re1='.*?'\t# Non-greedy match on filler\n",
    "        ####################\n",
    "        #self.numclasses\n",
    "        i=-1\n",
    "        for re2 in self.classList:\n",
    "            i = i+1\n",
    "            rg = re.compile(re1+re2,re.IGNORECASE|re.DOTALL)\n",
    "            m = rg.search(path)\n",
    "            if m:\n",
    "                classnum = i\n",
    "                break\n",
    "        return classnum\n",
    "            \n",
    "                \n",
    "        \n",
    "    \n",
    "    \n",
    "    def getBatch(self):\n",
    "        batchCount = 0\n",
    "        X = np.zeros([self.sequenceLength,self.batchsize,int(self.Xaxis/2),int(self.Yaxis/2)])\n",
    "        Y = np.zeros([self.batchsize])\n",
    "\n",
    "        for pathname in self.pathList:\n",
    "            \n",
    "            \n",
    "            v = av.open(pathname)\n",
    "            \n",
    "            self.current +=1\n",
    "            \n",
    "            if(videoDataset(self.rootDir).regexBatchnum(pathname)== True):\n",
    "                if pathname not in self.testdata:\n",
    "                    self.testdata.append(pathname)\n",
    "                continue\n",
    "\n",
    "            \n",
    "            stream = next(s for s in v.streams if s.type == 'video')\n",
    "            X_data = []\n",
    "            for packet in v.demux(stream):\n",
    "                for frame in packet.decode():\n",
    "                    # some other formats gray16be, bgr24, rgb24\n",
    "                    img = frame.to_nd_array(format='bgr24')\n",
    "                    gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                    \n",
    "                    X_data.append(gray_image)\n",
    "            \n",
    "            X_data = np.array(X_data)\n",
    "            aa = np.floor(np.linspace(1,X_data.shape[0],self.sequenceLength,endpoint = False))\n",
    "            sampledX = []\n",
    "            \n",
    "            for i in aa:\n",
    "                sampledX.append(X_data[int(i),:,:])\n",
    "            sampledX = np.array(sampledX)\n",
    "            \n",
    "            \n",
    "            #Reduced dimensions in resize_X\n",
    "            resize_X = []\n",
    "            \n",
    "            #Resizing the (sequence_length) number of images into half size. So that the output of CNN doesn't explode \n",
    "            for p in range(sampledX.shape[0]):\n",
    "                height, width = sampledX[p,:,:].shape\n",
    "                gray_image = cv2.resize(sampledX[p,:,:],(int(width/2), int(height/2)), interpolation = cv2.INTER_AREA)\n",
    "                resize_X.append(gray_image)\n",
    "            \n",
    "            resize_X = np.array(resize_X)\n",
    "            \n",
    "            \n",
    "            \n",
    "            #Now load array into the final batch array\n",
    "            X[:,batchCount,:,:] = resize_X\n",
    "            Y[batchCount] = int(videoDataset(self.rootDir).regexClass(pathname))\n",
    "            batchCount += 1\n",
    "            \n",
    "            if(batchCount == self.batchsize ):\n",
    "                return X,Y\n",
    "            \n",
    "    \n",
    "    def getTestData(self):\n",
    "        \n",
    "        TestData = []\n",
    "        TestClass = []\n",
    "        for test in self.testdata:\n",
    "            \n",
    "            v = av.open(test)\n",
    "            \n",
    "            stream = next(s for s in v.streams if s.type == 'video')\n",
    "            X_test = []\n",
    "            \n",
    "            for packet in v.demux(stream):\n",
    "                for frame in packet.decode():\n",
    "                    # some other formats gray16be, bgr24, rgb24\n",
    "                    img = frame.to_nd_array(format='bgr24')\n",
    "                    gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                    \n",
    "                    X_test.append(gray_image)\n",
    "            \n",
    "            X_test = np.array(X_test)\n",
    "            aa = np.floor(np.linspace(1,X_test.shape[0],self.sequenceLength,endpoint = False))\n",
    "            sampledXtest = []\n",
    "            \n",
    "            for i in aa:\n",
    "                sampledXtest.append(X_test[int(i),:,:])\n",
    "            sampledXtest = np.array(sampledXtest)\n",
    "            \n",
    "            \n",
    "            #Reduced dimensions in resize_X\n",
    "            resize_X = []\n",
    "            \n",
    "            #Resizing the (sequence_length) number of images into half size. So that the output of CNN doesn't explode \n",
    "            for p in range(sampledX.shape[0]):\n",
    "                height, width = sampledXtest[p,:,:].shape\n",
    "                gray_image = cv2.resize(sampledXtest[p,:,:],(int(width/2), int(height/2)), interpolation = cv2.INTER_AREA)\n",
    "                resize_X.append(gray_image)\n",
    "            \n",
    "            resize_X = np.array(resize_X)\n",
    "            \n",
    "            TestData.append(resize_X)\n",
    "            TestClass.append(int(videoDataset(self.rootDir).regexClass(test)))\n",
    "            \n",
    "        \n",
    "        TestData = np.array(TestData)\n",
    "        TestData = np.swapaxes(TestData,0,1)\n",
    "        TestClass = np.array(TestClass)\n",
    "        return TestData, TestClass\n",
    "    \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#torch.cuda.set_device(1)\n",
    "#torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "exp = 1\n",
    "writer = SummaryWriter()\n",
    "path = '/media/data/bimal/Arpan/original_data/'\n",
    "batchsize = 50\n",
    "seq_length = 5\n",
    "height = 192\n",
    "width = 240\n",
    "num_iter = 400\n",
    "\n",
    "#CNN parameters\n",
    "learning_rate = 0.0005\n",
    "kH = 5\n",
    "kW = 5\n",
    "noFilters1 = 16\n",
    "noFilters2 = 8\n",
    "padW = (kW-1)/2\n",
    "padH = (kH-1)/2\n",
    "cnn_output = 5760\n",
    "\n",
    "#RNN parameters\n",
    "hidden_size = 1200\n",
    "num_layers_RNN = 1\n",
    "num_classes = 11\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "DataLoader= videoDataset(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, noFilters1, noFilters2, kH, width):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, noFilters1, kernel_size= kH, padding= int((kH-1)/2)),\n",
    "            nn.BatchNorm2d(noFilters1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(noFilters1, noFilters2, kernel_size=kH, padding= int((kH-1)/2)),\n",
    "            nn.BatchNorm2d(noFilters2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        #self.fc = nn.Linear( int((width)/4 * (width)/4 *noFilters2), 11)\n",
    "        #softmax\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        #out = self.fc(out)\n",
    "        return out\n",
    "        \n",
    "cnn = CNN(noFilters1, noFilters2, kH, width)\n",
    "\n",
    "\n",
    "# RNN Model (Many-to-One)\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=False)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.soft = nn.Softmax()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Set initial states \n",
    "        h0 = Variable(torch.zeros(self.num_layers, x.size(1), self.hidden_size)) \n",
    "        c0 = Variable(torch.zeros(self.num_layers, x.size(1), self.hidden_size))\n",
    "        \n",
    "        # Forward propagate RNN\n",
    "        out, _ = self.lstm(x, (h0, c0)) \n",
    "        \n",
    "        \n",
    "        # Decode hidden state of last time step\n",
    "        output = self.fc(out.view(out.size(0)*out.size(1),out.size(2)))  \n",
    "        output = self.soft(output)\n",
    "        return output.view(out.size(0),out.size(1),output.size(1))\n",
    "\n",
    "rnn = RNN(cnn_output, hidden_size, num_layers_RNN, num_classes)\n",
    "\n",
    "# criterion = nn.MultiLabelSoftMarginLoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(list(rnn.parameters()) + list(cnn.parameters()), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bimal/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 1 , Loss value 2.398042\n",
      "Iteration number 10 , Loss value 2.375924\n",
      "Iteration number 20 , Loss value 2.394389\n",
      "Iteration number 30 , Loss value 2.317404\n",
      "Iteration number 40 , Loss value 2.401976\n",
      "Iteration number 50 , Loss value 2.402094\n",
      "Iteration number 60 , Loss value 2.321947\n",
      "Iteration number 70 , Loss value 2.396771\n",
      "Iteration number 80 , Loss value 2.289645\n",
      "Iteration number 90 , Loss value 2.435684\n",
      "Iteration number 100 , Loss value 2.415046\n",
      "Iteration number 110 , Loss value 2.314993\n",
      "Iteration number 120 , Loss value 2.434190\n",
      "Iteration number 130 , Loss value 2.422462\n",
      "Iteration number 140 , Loss value 2.351420\n",
      "Iteration number 150 , Loss value 2.405107\n",
      "Iteration number 160 , Loss value 2.333382\n",
      "Iteration number 180 , Loss value 2.405294\n",
      "Iteration number 190 , Loss value 2.379262\n",
      "Iteration number 200 , Loss value 2.367678\n",
      "Iteration number 210 , Loss value 2.386676\n",
      "Iteration number 220 , Loss value 2.387442\n",
      "Iteration number 230 , Loss value 2.443273\n",
      "Iteration number 240 , Loss value 2.359227\n",
      "Iteration number 250 , Loss value 2.432080\n",
      "Iteration number 260 , Loss value 2.391550\n",
      "Iteration number 270 , Loss value 2.376440\n",
      "Iteration number 280 , Loss value 2.432478\n",
      "Iteration number 290 , Loss value 2.384557\n",
      "Iteration number 300 , Loss value 2.270597\n",
      "Iteration number 310 , Loss value 2.359609\n",
      "Iteration number 140 , Loss value 2.044198\n",
      "Iteration number 150 , Loss value 2.219602\n",
      "Iteration number 160 , Loss value 2.097871\n",
      "Iteration number 170 , Loss value 2.134487\n",
      "Iteration number 180 , Loss value 2.119545\n",
      "Iteration number 190 , Loss value 2.072300\n",
      "Iteration number 200 , Loss value 2.079276\n",
      "Iteration number 210 , Loss value 2.190062\n",
      "Iteration number 220 , Loss value 2.016199\n",
      "Iteration number 230 , Loss value 2.158807\n",
      "Iteration number 240 , Loss value 2.152560\n",
      "Iteration number 250 , Loss value 2.010023\n",
      "Iteration number 260 , Loss value 2.132008\n",
      "Iteration number 270 , Loss value 2.115265\n",
      "Iteration number 280 , Loss value 2.023447\n",
      "Iteration number 290 , Loss value 2.013676\n",
      "Iteration number 300 , Loss value 2.098167\n",
      "Iteration number 310 , Loss value 1.990631\n",
      "Iteration number 320 , Loss value 2.031109\n",
      "Iteration number 330 , Loss value 2.076112\n",
      "Iteration number 340 , Loss value 2.042623\n",
      "Iteration number 350 , Loss value 2.114712\n",
      "Iteration number 360 , Loss value 2.091554\n",
      "Iteration number 370 , Loss value 2.018796\n",
      "Iteration number 380 , Loss value 1.977308\n",
      "Iteration number 390 , Loss value 2.009956\n",
      "Iteration number 400 , Loss value 1.972430\n",
      "Iteration number 1 , Loss value 1.965616\n",
      "Iteration number 10 , Loss value 2.030478\n",
      "Iteration number 20 , Loss value 1.994596\n",
      "Iteration number 30 , Loss value 1.956934\n",
      "Iteration number 40 , Loss value 1.920377\n",
      "Iteration number 50 , Loss value 1.932750\n",
      "Iteration number 60 , Loss value 1.887870\n",
      "Iteration number 70 , Loss value 1.937927\n",
      "Iteration number 80 , Loss value 1.941391\n",
      "Iteration number 90 , Loss value 1.842130\n",
      "Iteration number 100 , Loss value 1.792405\n",
      "Iteration number 110 , Loss value 1.796663\n",
      "Iteration number 120 , Loss value 1.980195\n",
      "Iteration number 130 , Loss value 1.839398\n",
      "Iteration number 140 , Loss value 1.834951\n",
      "Iteration number 150 , Loss value 1.861559\n",
      "Iteration number 160 , Loss value 1.770175\n",
      "Iteration number 170 , Loss value 1.801554\n",
      "Iteration number 180 , Loss value 1.806252\n",
      "Iteration number 190 , Loss value 1.779629\n",
      "Iteration number 200 , Loss value 1.733011\n",
      "Iteration number 210 , Loss value 1.818853\n",
      "Iteration number 220 , Loss value 1.725785\n",
      "Iteration number 230 , Loss value 1.728137\n",
      "Iteration number 240 , Loss value 1.774952\n",
      "Iteration number 250 , Loss value 1.703718\n",
      "Iteration number 260 , Loss value 1.725565\n",
      "Iteration number 270 , Loss value 1.665836\n",
      "Iteration number 280 , Loss value 1.632869\n",
      "Iteration number 290 , Loss value 1.667146\n",
      "Iteration number 300 , Loss value 1.685190\n",
      "Iteration number 310 , Loss value 1.757727\n",
      "Iteration number 320 , Loss value 1.730257\n",
      "Iteration number 330 , Loss value 1.641127\n",
      "Iteration number 340 , Loss value 1.620872\n",
      "Iteration number 350 , Loss value 1.696047\n",
      "Iteration number 360 , Loss value 1.624861\n",
      "Iteration number 370 , Loss value 1.581945\n",
      "Iteration number 380 , Loss value 1.682456\n",
      "Iteration number 390 , Loss value 1.577346\n",
      "Iteration number 400 , Loss value 1.582741\n",
      "Iteration number 1 , Loss value 1.558241\n",
      "Iteration number 10 , Loss value 1.578541\n",
      "Iteration number 20 , Loss value 1.553010\n",
      "Iteration number 30 , Loss value 1.554289\n",
      "Iteration number 40 , Loss value 1.550393\n",
      "Iteration number 50 , Loss value 1.547540\n",
      "Iteration number 60 , Loss value 1.546098\n",
      "Iteration number 70 , Loss value 1.547889\n",
      "Iteration number 80 , Loss value 1.546742\n",
      "Iteration number 90 , Loss value 1.544817\n",
      "Iteration number 100 , Loss value 1.546051\n",
      "Iteration number 110 , Loss value 1.545444\n",
      "Iteration number 120 , Loss value 1.544585\n",
      "Iteration number 130 , Loss value 1.547966\n",
      "Iteration number 140 , Loss value 1.563437\n",
      "Iteration number 150 , Loss value 1.544618\n",
      "Iteration number 160 , Loss value 1.544440\n",
      "Iteration number 170 , Loss value 1.544443\n",
      "Iteration number 180 , Loss value 1.544012\n",
      "Iteration number 190 , Loss value 1.544164\n",
      "Iteration number 200 , Loss value 1.545953\n",
      "Iteration number 210 , Loss value 1.543793\n",
      "Iteration number 220 , Loss value 1.543907\n",
      "Iteration number 230 , Loss value 1.543980\n",
      "Iteration number 240 , Loss value 1.543816\n",
      "Iteration number 250 , Loss value 1.544871\n",
      "Iteration number 260 , Loss value 1.543530\n",
      "Iteration number 270 , Loss value 1.544200\n",
      "Iteration number 280 , Loss value 1.543730\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3d463e411768>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(6):\n",
    "    if((epoch + 1)%2 == 0 ):\n",
    "        scheduler.step()\n",
    "    for iteration in range(num_iter):\n",
    "        X_data,Y_data = DataLoader.getBatch()\n",
    "    #     Y_onehot = (np.arange(num_classes) == Y_data[:,None]).astype(np.float32)\n",
    "\n",
    "        X_data = Variable(torch.FloatTensor(X_data))\n",
    "        Y_data = Variable(torch.Tensor(Y_data).long(), requires_grad=False)\n",
    "\n",
    "        RNNinput = np.zeros([seq_length,batchsize,cnn_output])\n",
    "        RNNinput = Variable(torch.from_numpy(RNNinput).float())\n",
    "\n",
    "    #     RNNoutput = np.zeros([seq_length,batchsize,num_classes])\n",
    "    #     RNNoutput = Variable(torch.from_numpy(RNNoutput).float())\n",
    "\n",
    "        T = []\n",
    "        temp = []\n",
    "        for i in range(seq_length):\n",
    "            T.append(X_data[i,:,:,:].unsqueeze(1))\n",
    "\n",
    "        for t in T:\n",
    "            temp.append(cnn(t))\n",
    "\n",
    "        RNNinput = temp[0].unsqueeze(0)\n",
    "        for i in range(1, len(temp)):\n",
    "            RNNinput = torch.cat((RNNinput, temp[i].unsqueeze(0)), 0)\n",
    "\n",
    "    #     for k in range(batchsize):\n",
    "    #         for m in range(len(temp)):\n",
    "    #             TEMP = temp[m]\n",
    "    #             RNNinput[m,k,:] = TEMP[k,:]\n",
    "\n",
    "        Y_out = rnn(RNNinput)\n",
    "        total_loss = 0\n",
    "        for q in range(seq_length):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = Y_out[q,:,:]\n",
    "            loss = criterion(output, Y_data)\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.data[0]\n",
    "\n",
    "\n",
    "        total_loss = total_loss/seq_length\n",
    "\n",
    "        writer.add_scalar('DVS/train_loss', total_loss, iteration + epoch*num_iter)\n",
    "        if ((iteration+1)%10 == 0 or iteration == 0):\n",
    "            print(\"Iteration number %d , Loss value %f\"%(iteration+1, total_loss))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH_CNN = './TrainModel/' + str(exp) + '-' + str(DataLoader.k) + '-CNN'\n",
    "SAVE_PATH_RNN = './TrainModel/' + str(exp) + '-' + str(DataLoader.k) + '-RNN'\n",
    "torch.save(cnn.state_dict(), SAVE_PATH_CNN)\n",
    "torch.save(rnn.state_dict(), SAVE_PATH_RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current = 0\n",
    "for path in X.pathList:\n",
    "    print(int(X.regexClass(path)))\n",
    "    current += 1\n",
    "    \n",
    "    if(current>=2000):\n",
    "        break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = []\n",
    "file = []\n",
    "path = '/media/data/bimal/Arpan/original_data/'\n",
    "for _, dirnames, filenames in os.walk(path):\n",
    "            name.append(dirnames)\n",
    "            file.append(filenames)\n",
    "name = name[0]\n",
    "newpath = []\n",
    "\n",
    "for i in range(len(name)):    \n",
    "        for files in file[i+1]:\n",
    "             pathn = path + name[i]+'/' + files\n",
    "             newpath.append(pathn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        classnum = 0\n",
    "                \n",
    "        re1='.*?'\t# Non-greedy match on filler\n",
    "        ####################\n",
    "        #self.numclasses\n",
    "        i=0\n",
    "        for re2 in classList:\n",
    "            i=i+1\n",
    "            rg = re.compile(re1+re2,re.IGNORECASE|re.DOTALL)\n",
    "            m = rg.search(newpath[200])\n",
    "            if m:\n",
    "                classnum = i\n",
    "                break\n",
    "        print(classnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [4,2,3,1,5,6]\n",
    "if 7 not in a:\n",
    "    a.append(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testtt = []\n",
    "\n",
    "for p in range(5):\n",
    "    testtt.append(np.random.rand(4,3,3))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.swapaxes(ppp,0,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

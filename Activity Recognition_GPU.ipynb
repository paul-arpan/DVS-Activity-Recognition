{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataLoader class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import av\n",
    "import re\n",
    "from itertools import cycle\n",
    "from random import shuffle\n",
    "\n",
    "class videoDataset():\n",
    "    \"\"\"Dataset Class for Loading Video\"\"\"\n",
    "\n",
    "    def __init__(self, path, k=1, batchsize=10, seq_length=5):\n",
    "        \n",
    "        self.rootDir = path\n",
    "        name=[]\n",
    "        file=[]\n",
    "        for _, dirnames, filenames in os.walk(path):\n",
    "            name.append(dirnames)\n",
    "            file.append(filenames)\n",
    "        name = name[0]\n",
    "\n",
    "        newpath = []\n",
    "\n",
    "        for i in range(len(name)):    \n",
    "            for files in file[i+1]:\n",
    "                pathn = path + name[i]+'/' + files\n",
    "                newpath.append(pathn)\n",
    "                \n",
    "        shuffle(newpath)        \n",
    "        self.sequenceLength = seq_length\n",
    "        self.classList=['(0_Basketball)','(1_Biking)','(2_Diving)','(3_GolfSwing)','(4_HorseRiding)','(5_SoccerJuggling)','(6_Swing)','(7_TennisSwing)','(8_TrampolineJumping)','(9_VolleyballSpiking)','(10_WalkingWithDog)']\t# Word 1   \n",
    "        self.Xaxis = 192\n",
    "        self.Yaxis = 240\n",
    "        self.minFrames = 31        \n",
    "        self.pathList = cycle(newpath)\n",
    "        self.testdata = []\n",
    "        self.batchsize = batchsize\n",
    "        self.k = k\n",
    "        self.current=0\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    " \n",
    "    \n",
    "    def frameLength(newpath):\n",
    "        v = av.open(newpath)\n",
    "        stream = next(s for s in v.streams if s.type == 'video')\n",
    "        #X_data = []\n",
    "        for packet in v.demux(stream):\n",
    "            for frame in packet.decode():\n",
    "                continue\n",
    "        return frame.index\n",
    "    \n",
    "    def setK(self,num):\n",
    "        self.k = num\n",
    "    \n",
    " \n",
    "    def regexBatchnum(self,path):\n",
    "        re1='.*?'\t# Non-greedy match on filler\n",
    "        re2='g'\t# Uninteresting: c\n",
    "        re3='.*?'\t# Non-greedy match on filler\n",
    "        re4='g'\t# Uninteresting: c\n",
    "        re5='.*?'\t# Non-greedy match on filler\n",
    "        re6='g'\t# Uninteresting: c\n",
    "        re7='.*?'\t# Non-greedy match on filler\n",
    "        re8='(g)'\t# Any Single Character 1        \n",
    "\n",
    "        re9= '(' + str(self.k).zfill(2) + ')'\t# Integer Number 1\n",
    "        \n",
    "        rg = re.compile(re1+re2+re3+re4+re5+re6+re7+re8+re9,re.IGNORECASE|re.DOTALL)\n",
    "        m = rg.search(path)\n",
    "        \n",
    "        if(m==None):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    \n",
    "    def regexClass(self,path):\n",
    "        \n",
    "        classnum = 0\n",
    "                \n",
    "        re1='.*?'\t# Non-greedy match on filler\n",
    "        ####################\n",
    "        #self.numclasses\n",
    "        i=-1\n",
    "        for re2 in self.classList:\n",
    "            i = i+1\n",
    "            rg = re.compile(re1+re2,re.IGNORECASE|re.DOTALL)\n",
    "            m = rg.search(path)\n",
    "            if m:\n",
    "                classnum = i\n",
    "                break\n",
    "        return classnum\n",
    "            \n",
    "                \n",
    "        \n",
    "    \n",
    "    \n",
    "    def getBatch(self):\n",
    "        batchCount = 0\n",
    "        X = np.zeros([self.sequenceLength,self.batchsize,int(self.Xaxis/2),int(self.Yaxis/2)])\n",
    "        Y = np.zeros([self.batchsize])\n",
    "\n",
    "        for pathname in self.pathList:\n",
    "            \n",
    "            \n",
    "            v = av.open(pathname)\n",
    "            \n",
    "            self.current +=1\n",
    "            \n",
    "            if(self.regexBatchnum(pathname)== True):\n",
    "                if pathname not in self.testdata:\n",
    "                    self.testdata.append(pathname)\n",
    "                continue\n",
    "\n",
    "            \n",
    "            stream = next(s for s in v.streams if s.type == 'video')\n",
    "            X_data = []\n",
    "            for packet in v.demux(stream):\n",
    "                for frame in packet.decode():\n",
    "                    # some other formats gray16be, bgr24, rgb24\n",
    "                    img = frame.to_nd_array(format='bgr24')\n",
    "                    gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                    \n",
    "                    X_data.append(gray_image)\n",
    "            \n",
    "            X_data = np.array(X_data)\n",
    "            aa = np.floor(np.linspace(1,X_data.shape[0],self.sequenceLength,endpoint = False))\n",
    "            sampledX = []\n",
    "            \n",
    "            for i in aa:\n",
    "                sampledX.append(X_data[int(i),:,:])\n",
    "            sampledX = np.array(sampledX)\n",
    "            \n",
    "            \n",
    "            #Reduced dimensions in resize_X\n",
    "            resize_X = []\n",
    "            \n",
    "            #Resizing the (sequence_length) number of images into half size. So that the output of CNN doesn't explode \n",
    "            for p in range(sampledX.shape[0]):\n",
    "                height, width = sampledX[p,:,:].shape\n",
    "                gray_image = cv2.resize(sampledX[p,:,:],(int(width/2), int(height/2)), interpolation = cv2.INTER_AREA)\n",
    "                resize_X.append(gray_image)\n",
    "            \n",
    "            resize_X = np.array(resize_X)\n",
    "            \n",
    "            \n",
    "            \n",
    "            #Now load array into the final batch array\n",
    "            X[:,batchCount,:,:] = resize_X\n",
    "            Y[batchCount] = int(self.regexClass(pathname))\n",
    "            batchCount += 1\n",
    "            \n",
    "            if(batchCount == self.batchsize ):\n",
    "                return X,Y\n",
    "            \n",
    "    \n",
    "    def getTestData(self):\n",
    "        \n",
    "        TestData = []\n",
    "        TestClass = []\n",
    "       \n",
    "        \n",
    "        for test in self.testdata:\n",
    "            \n",
    "            v = av.open(test)\n",
    "            \n",
    "            stream = next(s for s in v.streams if s.type == 'video')\n",
    "            X_test = []\n",
    "            \n",
    "            for packet in v.demux(stream):\n",
    "                for frame in packet.decode():\n",
    "                    # some other formats gray16be, bgr24, rgb24\n",
    "                    img = frame.to_nd_array(format='bgr24')\n",
    "                    gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                    \n",
    "                    X_test.append(gray_image)\n",
    "            \n",
    "            X_test = np.array(X_test)\n",
    "            aa = np.floor(np.linspace(1,X_test.shape[0],self.sequenceLength,endpoint = False))\n",
    "            sampledXtest = []\n",
    "            \n",
    "            for i in aa:\n",
    "                sampledXtest.append(X_test[int(i),:,:])\n",
    "            sampledXtest = np.array(sampledXtest)\n",
    "            \n",
    "            \n",
    "            #Reduced dimensions in resize_X\n",
    "            resize_X = []\n",
    "            \n",
    "            #Resizing the (sequence_length) number of images into half size. So that the output of CNN doesn't explode \n",
    "            for p in range(sampledXtest.shape[0]):\n",
    "                height, width = sampledXtest[p,:,:].shape\n",
    "                gray_image = cv2.resize(sampledXtest[p,:,:],(int(width/2), int(height/2)), interpolation = cv2.INTER_AREA)\n",
    "                resize_X.append(gray_image)\n",
    "            \n",
    "            resize_X = np.array(resize_X)\n",
    "            \n",
    "            TestData.append(resize_X)\n",
    "            TestClass.append(int(self.regexClass(test)))\n",
    "            \n",
    "        \n",
    "        TestData = np.array(TestData)\n",
    "        TestData = np.swapaxes(TestData,0,1)\n",
    "        TestClass = np.array(TestClass)\n",
    "        return TestData, TestClass\n",
    "    \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "torch.cuda.set_device(1)\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "dtype = torch.cuda.FloatTensor\n",
    "\n",
    "exp = 3\n",
    "writer = SummaryWriter()\n",
    "path = '/media/data/bimal/Arpan/original_data/'\n",
    "batchsize = 30\n",
    "seq_length = 5\n",
    "height = 192\n",
    "width = 240\n",
    "num_iter = 400\n",
    "K = 1\n",
    "\n",
    "#CNN parameters\n",
    "learning_rate = 0.0005\n",
    "kH = 5\n",
    "kW = 5\n",
    "noFilters1 = 16\n",
    "noFilters2 = 8\n",
    "padW = (kW-1)/2\n",
    "padH = (kH-1)/2\n",
    "cnn_output = 5760\n",
    "\n",
    "#RNN parameters\n",
    "hidden_size = 1200\n",
    "num_layers_RNN = 1\n",
    "num_classes = 11\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "DataLoader= videoDataset(path, K, batchsize, seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, noFilters1, noFilters2, kH, width):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, noFilters1, kernel_size= kH, padding= int((kH-1)/2)),\n",
    "            nn.BatchNorm2d(noFilters1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(noFilters1, noFilters2, kernel_size=kH, padding= int((kH-1)/2)),\n",
    "            nn.BatchNorm2d(noFilters2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        #self.fc = nn.Linear( int((width)/4 * (width)/4 *noFilters2), 11)\n",
    "        #softmax\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        #out = self.fc(out)\n",
    "        return out\n",
    "        \n",
    "cnn = CNN(noFilters1, noFilters2, kH, width)\n",
    "cnn.cuda()\n",
    "\n",
    "# RNN Model (Many-to-One)\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=False)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.soft = nn.Softmax()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Set initial states \n",
    "        h0 = Variable(torch.zeros(self.num_layers, x.size(1), self.hidden_size)) \n",
    "        c0 = Variable(torch.zeros(self.num_layers, x.size(1), self.hidden_size))\n",
    "        \n",
    "        # Forward propagate RNN\n",
    "        out, _ = self.lstm(x, (h0, c0)) \n",
    "        \n",
    "        \n",
    "        # Decode hidden state of last time step\n",
    "        output = self.fc(out.view(out.size(0)*out.size(1),out.size(2)))  \n",
    "        output = self.soft(output)\n",
    "        return output.view(out.size(0),out.size(1),output.size(1))\n",
    "\n",
    "rnn = RNN(cnn_output, hidden_size, num_layers_RNN, num_classes)\n",
    "rnn.cuda()\n",
    "\n",
    "# criterion = nn.MultiLabelSoftMarginLoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(list(rnn.parameters()) + list(cnn.parameters()), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bimal/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 1 epoch 0, Loss value 2.398541 Kvalue 1\n",
      "Iteration number 10 epoch 0, Loss value 2.403050 Kvalue 1\n",
      "Iteration number 20 epoch 0, Loss value 2.467260 Kvalue 1\n",
      "Iteration number 30 epoch 0, Loss value 2.320493 Kvalue 1\n",
      "Iteration number 40 epoch 0, Loss value 2.337902 Kvalue 1\n",
      "Iteration number 50 epoch 0, Loss value 2.279891 Kvalue 1\n"
     ]
    }
   ],
   "source": [
    "ClassAcc = []\n",
    "for Kval in range(25):\n",
    "    DataLoader.k = Kval + 1\n",
    "    \n",
    "    cnn = CNN(noFilters1, noFilters2, kH, width)\n",
    "    cnn.cuda()\n",
    "    rnn = RNN(cnn_output, hidden_size, num_layers_RNN, num_classes)\n",
    "    rnn.cuda()\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(list(rnn.parameters()) + list(cnn.parameters()), lr=learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.5)\n",
    "    \n",
    "    \n",
    "\n",
    "    for epoch in range(4):\n",
    "        if((epoch + 1)%2 == 0 ):\n",
    "            scheduler.step()\n",
    "        for iteration in range(num_iter):\n",
    "            X_data,Y_data = DataLoader.getBatch()\n",
    "        #     Y_onehot = (np.arange(num_classes) == Y_data[:,None]).astype(np.float32)\n",
    "\n",
    "            X_data = Variable(torch.FloatTensor(X_data).cuda())\n",
    "            Y_data = Variable(torch.Tensor(Y_data).long().cuda(), requires_grad=False)\n",
    "\n",
    "            RNNinput = np.zeros([seq_length,batchsize,cnn_output])\n",
    "            RNNinput = Variable(torch.from_numpy(RNNinput).float().cuda())\n",
    "\n",
    "        #     RNNoutput = np.zeros([seq_length,batchsize,num_classes])\n",
    "        #     RNNoutput = Variable(torch.from_numpy(RNNoutput).float())\n",
    "\n",
    "            T = []\n",
    "            temp = []\n",
    "            for i in range(seq_length):\n",
    "                T.append(X_data[i,:,:,:].unsqueeze(1))\n",
    "\n",
    "            for t in T:\n",
    "                temp.append(cnn(t))\n",
    "\n",
    "            RNNinput = temp[0].unsqueeze(0)\n",
    "            for i in range(1, len(temp)):\n",
    "                RNNinput = torch.cat((RNNinput, temp[i].unsqueeze(0)), 0)\n",
    "\n",
    "        #     for k in range(batchsize):\n",
    "        #         for m in range(len(temp)):\n",
    "        #             TEMP = temp[m]\n",
    "        #             RNNinput[m,k,:] = TEMP[k,:]\n",
    "\n",
    "            Y_out = rnn(RNNinput)\n",
    "            total_loss = 0\n",
    "            for q in range(seq_length):\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                output = Y_out[q,:,:]\n",
    "                loss = criterion(output, Y_data)\n",
    "                loss.backward(retain_graph=True)\n",
    "                optimizer.step()\n",
    "                total_loss += loss.data[0]\n",
    "\n",
    "\n",
    "            total_loss = total_loss/seq_length\n",
    "\n",
    "            writer.add_scalar('DVS/train_loss', total_loss, iteration + epoch*num_iter)\n",
    "            if ((iteration+1)%10 == 0 or iteration == 0):\n",
    "                print(\"Iteration number %d epoch %d, Loss value %f Kvalue %d\"%(iteration+1, epoch, total_loss, Kval+1 ))\n",
    "    \n",
    "    \n",
    "    ###########################################################################################################\n",
    "    X_test, Y_test = DataLoader.getTestData()\n",
    "    X_test = Variable(torch.FloatTensor(X_test).cuda())\n",
    "    \n",
    "    T = []\n",
    "    temp = []\n",
    "    for i in range(seq_length):\n",
    "        T.append(X_test[i,:,:,:].unsqueeze(1))\n",
    "\n",
    "    for t in T:\n",
    "        temp.append(cnn(t))\n",
    "\n",
    "    RNNtest = temp[0].unsqueeze(0)\n",
    "    for i in range(1, len(temp)):\n",
    "        RNNtest = torch.cat((RNNtest, temp[i].unsqueeze(0)), 0)\n",
    "    \n",
    "    Y_predict = rnn(RNNtest)\n",
    "    \n",
    "    \n",
    "    correct = 0\n",
    "    \n",
    "    for q in range(seq_length):\n",
    "        _ , pre = torch.max(Y_predict[q,:,:].data, 1)\n",
    "        correct += (Y_test == pre).sum()\n",
    "    \n",
    "    ClassAcc.append(correct / (len(pre)*seq_length))\n",
    "    #writer.add_scalar('DVS/classification', ClassAcc, Kval + 1)\n",
    "    print('Classification accuracy %d'%( 100*correct / (len(pre)*seq_length) ))\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH_CNN = '/media/data/bimal/Arpan/TrainModel/' + str(exp) + '-' + str(DataLoader.k) + '-CNN'\n",
    "SAVE_PATH_RNN = '/media/data/bimal/Arpan/TrainModel/' + str(exp) + '-' + str(DataLoader.k) + '-RNN'\n",
    "torch.save(cnn.state_dict(), SAVE_PATH_CNN)\n",
    "torch.save(rnn.state_dict(), SAVE_PATH_RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "\n",
    "for i in range(10):\n",
    "    test.append(np.random.randn(5, 3 ,3))\n",
    "test = np.array(test)\n",
    "test = np.swapaxes(test,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(DataLoader.testdata)\n",
    "TestData = []\n",
    "TestClass = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    X_test, Y_test = DataLoader.getTestData()\n",
    "    X_test = Variable(torch.FloatTensor(X_test).cuda())\n",
    "    \n",
    "    T = []\n",
    "    temp = []\n",
    "    for i in range(seq_length):\n",
    "        T.append(X_test[i,:,:,:].unsqueeze(1))\n",
    "\n",
    "    for t in T:\n",
    "        temp.append(cnn(t))\n",
    "\n",
    "    RNNtest = temp[0].unsqueeze(0)\n",
    "    for i in range(1, len(temp)):\n",
    "        RNNtest = torch.cat((RNNtest, temp[i].unsqueeze(0)), 0)\n",
    "    \n",
    "    Y_predict = rnn(RNNtest)\n",
    "    \n",
    "    \n",
    "    correct = 0\n",
    "    \n",
    "    for q in range(seq_length):\n",
    "        _ , pre = torch.max(Y_predict[q,:,:].data, 1)\n",
    "        correct += (Y_test == pre).sum()\n",
    "    \n",
    "    ClassAcc.append(correct / (len(pre)*seq_length))\n",
    "    writer.add_scalar('DVS/classification', ClassAcc, Kval + 1)\n",
    "    print('Classification accuracy %d'%( 100*correct / (len(pre)*seq_length) ))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_onehotD = (np.arange(num_classes) == Y_D[:,None]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ , pred = torch.max(Y_onehotD.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ClassAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_onehotD = Variable(torch.Tensor(Y_onehotD).cuda(), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_out[1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for q in range(seq_length):\n",
    "        _ , pre = torch.max(Y_out[q,:,:].data, 1)\n",
    "        _ , out = torch.max(Y_onehotD.data, 1)\n",
    "        correct += (pred == pre).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct / (len(pre)*seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
